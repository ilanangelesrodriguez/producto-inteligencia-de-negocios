{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## [1. Import Needed Modules](#import) ##\n",
    "## [2 Concept for Callback Approach](#concept) ##\n",
    "## [3. Define function to print text in rgb foreground and background colors](#pc) ##\n",
    "## [4 Define a function to plot the number of images for each label in a dataframel](#pcounts) ##\n",
    "## [5. Read in images and create a dataframe of image paths and class labels](#makedf) ## \n",
    "## [6. Balance the trainning set](#Balance) ##\n",
    "## [7. Create train, test and validation generators](#generators) ## \n",
    "## [8. Create a function to show Training Image Samples](#show) ## \n",
    "## [9 Create a function to calculate the F1 score metric](#f1metric) ##\n",
    "## [10. Create the Model](#model) ## \n",
    "## [11. Create a custom Keras callback to continue or halt training](#callback) ## \n",
    "## [12. Instantiate custom callback ](#callbacks) ##\n",
    "## [13. Train the model](#train) ##\n",
    "## [14. Define a function to plot the training data](#plot) ##\n",
    "## [15. Make predictions on test set, create Confusion Matrix and Classification Report](#result) ##\n",
    "## [16 Print the list of misclassified test files](#perrors) ##\n",
    "## [17 Show misclassified test images and sample of predicted class](#serrors) ##\n",
    "## [18 Save the model](#save) ##\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"import\"></a>\n",
    "# <center>Import Need Modules</center>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T23:16:50.365386Z",
     "iopub.status.busy": "2022-11-08T23:16:50.365003Z",
     "iopub.status.idle": "2022-11-08T23:16:50.378269Z",
     "shell.execute_reply": "2022-11-08T23:16:50.377021Z",
     "shell.execute_reply.started": "2022-11-08T23:16:50.365355Z"
    },
    "trusted": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import shutil\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from IPython.display import YouTubeVideo\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)  # or 1000\n",
    "pd.set_option('display.max_rows', None)  # or 1000\n",
    "pd.set_option('display.max_colwidth', None)  # or 199\n",
    "print('All modules have been imported')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"concept\"></a>\n",
    "# <center>Custom Callback Concept</center>\n",
    "This notebook implements a custom callback to adjust the learning rate during training.  \n",
    "The callback has a parameter dwell. If dwell is set to True, the callback monitors the  \n",
    "validation loss. It keeps track of the lowest validation loss thus far achieved as you run  \n",
    "through each epoch and stores this as the lowest loss and also stores the weights for that  \n",
    "epoch as the best weights. At the end of an epoch the validation loss for that epoch is  \n",
    "compared with the lowest loss. If the validation loss at the end of the current epoch is  \n",
    "less than the lowest loss than it becomes the lowest loss and the weights of the current  \n",
    "epoch become the best weights  \n",
    "  \n",
    "If the validation loss at the end of the current epoch is greator than the lowest loss    \n",
    "this implies you have moved to a location in Nspace(N is the number of trainable parameters    \n",
    "on the validation cost function surface that is less favorable(higher cost) than the position  \n",
    "in Nspace defined by the best weights. Therefore why move the models weights to this less  \n",
    "favorable location? Better to reset the models weights to the best weights, then lower the  \n",
    "learning rate and run more epochs. The new learning rate is set to new_lr=current_lr * factor  \n",
    "where factor is a user specified parameter in the instantiation of the callback. By default  \n",
    "it is set to .04 and by default dwell is set to True.  \n",
    "  \n",
    "At the end of training the callback always returns your model with the weights set to the  \n",
    "best weights. The callback provides a feature where it periodically queries the user to  \n",
    "either contine and optionally manually specify a new learning rate or halt training.  \n",
    "During training the calback provides useful information on the percent improvement in the  \n",
    "validation loss for each epoch. The is useful to decide when to halt training or manually  \n",
    "specifying a new learning rate.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pc\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pc\"></a>\n",
    "## <center>Define a function to print text in specified rgb foreground and background colors</center>\n",
    "### Add some PZAZZ to your printed output with this function  \n",
    "form of the call is:  print_in_color(txt_msg, fore_tupple, back_tupple where:\n",
    "* txt_msg is the string to be printed out  \n",
    "* fore_tuple is tuple of the form (r,g,b) specifying the foreground color of the text\n",
    "* back_tuple is tuple of the form (r,g,b) specifying the background color of the text"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T23:16:50.381061Z",
     "iopub.status.busy": "2022-11-08T23:16:50.380002Z",
     "iopub.status.idle": "2022-11-08T23:16:50.393022Z",
     "shell.execute_reply": "2022-11-08T23:16:50.391947Z",
     "shell.execute_reply.started": "2022-11-08T23:16:50.381005Z"
    },
    "trusted": true
   },
   "source": [
    "def print_in_color(txt_msg,fore_tupple=(0,255,255),back_tupple=(100,100,100)):\n",
    "    #prints the text_msg in the foreground color specified by fore_tupple with the background specified by back_tupple \n",
    "    #text_msg is the text, fore_tupple is foregroud color tupple (r,g,b), back_tupple is background tupple (r,g,b)\n",
    "    # default parameter print in cyan foreground and gray background\n",
    "    rf,gf,bf=fore_tupple\n",
    "    rb,gb,bb=back_tupple\n",
    "    msg='{0}' + txt_msg\n",
    "    mat='\\33[38;2;' + str(rf) +';' + str(gf) + ';' + str(bf) + ';48;2;' + str(rb) + ';' +str(gb) + ';' + str(bb) +'m' \n",
    "    print(msg .format(mat), flush=True)\n",
    "    print('\\33[0m', flush=True) # returns default print color to back to black\n",
    "    return\n",
    "\n",
    "# example default print\n",
    "msg='test of default colors'\n",
    "print_in_color(msg)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pcounts\"></a>\n",
    "## <center>Define a function that plots value counts for a column in a dataframe</center>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T23:16:50.395273Z",
     "iopub.status.busy": "2022-11-08T23:16:50.394534Z",
     "iopub.status.idle": "2022-11-08T23:16:50.405884Z",
     "shell.execute_reply": "2022-11-08T23:16:50.404839Z",
     "shell.execute_reply.started": "2022-11-08T23:16:50.395235Z"
    },
    "trusted": true
   },
   "source": [
    "def plot_label_count (df, column):\n",
    "    vcounts=df[column].value_counts()\n",
    "    labels=vcounts.keys().tolist()    \n",
    "    values=vcounts.tolist() \n",
    "    plt.figure(figsize=(20,5))\n",
    "    form = {'family': 'serif', 'color': 'blue', 'size': 25} \n",
    "    plt.bar(labels, values)\n",
    "    plt.title('Images per label', fontsize= 24, color='blue')\n",
    "    plt.xticks(rotation=90, fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.xlabel(\"Labels\", fontdict=form)\n",
    "    plt.ylabel('Number of Images', fontdict=form)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"makedf\"></a>\n",
    "# <center>Read in data and create train, test and validation data frames</center>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T23:16:50.410163Z",
     "iopub.status.busy": "2022-11-08T23:16:50.409028Z",
     "iopub.status.idle": "2022-11-08T23:16:58.843773Z",
     "shell.execute_reply": "2022-11-08T23:16:58.842601Z",
     "shell.execute_reply.started": "2022-11-08T23:16:50.410121Z"
    },
    "trusted": true
   },
   "source": [
    "def make_dataframes(train_dir,test_dir, val_dir):\n",
    "    bad_images=[]\n",
    "    if test_dir == None and val_dir==None:\n",
    "        dirlist=[train_dir]\n",
    "        names = ['train']\n",
    "    elif test_dir == None:\n",
    "        dirlist=[train_dir,  val_dir]\n",
    "        names=['train', 'valid']\n",
    "    elif val_dir == None:\n",
    "        dirlist=[train_dir,  test_dir]\n",
    "        names=['train', 'test'] \n",
    "    else:\n",
    "        dirlist=[train_dir, test_dir, val_dir]\n",
    "        names=['train','test', 'valid']\n",
    "    zipdir=zip(names, dirlist)\n",
    "    for name,d in zipdir:\n",
    "        filepaths=[]\n",
    "        labels=[]\n",
    "        classlist=sorted(os.listdir(d) )       \n",
    "        for klass in classlist:\n",
    "            classpath=os.path.join(d, klass)           \n",
    "            flist=sorted(os.listdir(classpath)) \n",
    "            desc=f'{name:6s}-{klass:25s}'\n",
    "            for f in tqdm(flist, ncols=130,desc=desc, unit='files', colour='blue'):\n",
    "                fpath=os.path.join(classpath,f)\n",
    "                try:\n",
    "                    img=plt.imread(fpath)\n",
    "                    shape=img.shape\n",
    "                    filepaths.append(fpath)\n",
    "                    labels.append(klass)\n",
    "                except:\n",
    "                    print (fpath, ' is an invalid image file')\n",
    "                    bad_images.append(fpath)\n",
    "        Fseries=pd.Series(filepaths, name='filepaths')\n",
    "        Lseries=pd.Series(labels, name='labels')\n",
    "        df=pd.concat([Fseries, Lseries], axis=1) \n",
    "        if name =='valid':\n",
    "            valid_df=df\n",
    "        elif name == 'test':\n",
    "            test_df=df\n",
    "        else:\n",
    "            if test_dir == None and val_dir == None:\n",
    "                pdf=df\n",
    "                train_df, dummy_df=train_test_split(pdf, train_size=.8, shuffle=True, random_state=123, stratify=pdf['labels'])\n",
    "                valid_df, test_df=train_test_split(dummy_df, train_size=.5, shuffle=True, random_state=123, stratify=dummy_df['labels'])\n",
    "            elif test_dir == None:\n",
    "                pdf=df\n",
    "                train_df,test_df=train_test_split(pdf, train_size=.8, shuffle=True, random_state=123, stratify=pdf['labels'])\n",
    "            else : # create a  validation dataframe\n",
    "                pdf=df\n",
    "                train_df,valid_df=train_test_split(pdf, train_size=.8, shuffle=True, random_state=123, stratify=pdf['labels'])\n",
    "    classes=sorted(train_df['labels'].unique())\n",
    "    class_count=len(classes)\n",
    "    sample_df=train_df.sample(n=100, replace=False)\n",
    "    # calculate the average image height and with\n",
    "    ht=0\n",
    "    wt=0\n",
    "    count=0\n",
    "    for i in range(len(sample_df)):\n",
    "        fpath=sample_df['filepaths'].iloc[i]\n",
    "        try:\n",
    "            img=cv2.imread(fpath)\n",
    "            h=img.shape[0]\n",
    "            w=img.shape[1]\n",
    "            wt +=w\n",
    "            ht +=h\n",
    "            count +=1\n",
    "        except:\n",
    "            pass\n",
    "    have=int(ht/count)\n",
    "    wave=int(wt/count)\n",
    "    aspect_ratio=have/wave\n",
    "    print('number of classes in processed dataset= ', class_count)    \n",
    "    counts=list(train_df['labels'].value_counts())    \n",
    "    print('the maximum files in any class in train_df is ', max(counts), '  the minimum files in any class in train_df is ', min(counts))\n",
    "    print('train_df length: ', len(train_df), '  test_df length: ', len(test_df), '  valid_df length: ', len(valid_df))  \n",
    "    print('average image height= ', have, '  average image width= ', wave, ' aspect ratio h/w= ', aspect_ratio)    \n",
    "    return train_df, test_df, valid_df, classes, class_count\n",
    "\n",
    "test_dir = r'../input/grapesdevelopmentstages/GrapesDevelopmentStages/v0.1/Classification/test'\n",
    "val_dir= r'../input/grapesdevelopmentstages/GrapesDevelopmentStages/v0.1/Classification/validation' # if there is no validation directory set val_dir = None, a valid_df dataframe will be created from train_df\n",
    "train_dir= r'../input/grapesdevelopmentstages/GrapesDevelopmentStages/v0.1/Classification/train' # if there is no test directory set test_dir = None, a test_df dataframe will be created from train_df\n",
    "\n",
    "train_df, test_df, valid_df, classes, class_count=make_dataframes(train_dir,test_dir, val_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets look at the number of image samples for each label"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T23:16:58.846770Z",
     "iopub.status.busy": "2022-11-08T23:16:58.846149Z",
     "iopub.status.idle": "2022-11-08T23:16:59.093027Z",
     "shell.execute_reply": "2022-11-08T23:16:59.092078Z",
     "shell.execute_reply.started": "2022-11-08T23:16:58.846730Z"
    },
    "trusted": true
   },
   "source": [
    "if len(train_df['labels'].unique())<20: # Over 20 labels the plot is to hard to understand\n",
    "    plot_label_count (train_df, 'labels')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"trim\"></a>\n",
    "## <center>Trim train_df so no class has more than 400 images </center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T23:16:59.095025Z",
     "iopub.status.busy": "2022-11-08T23:16:59.094655Z",
     "iopub.status.idle": "2022-11-08T23:16:59.117141Z",
     "shell.execute_reply": "2022-11-08T23:16:59.116109Z",
     "shell.execute_reply.started": "2022-11-08T23:16:59.094988Z"
    },
    "trusted": true
   },
   "source": [
    "def trim(df, max_samples, min_samples, column):\n",
    "    df=df.copy()\n",
    "    classes=df[column].unique()\n",
    "    class_count=len(classes)\n",
    "    length=len(df)\n",
    "    print ('dataframe initially is of length ',length, ' with ', class_count, ' classes')\n",
    "    groups=df.groupby(column)    \n",
    "    trimmed_df = pd.DataFrame(columns = df.columns)\n",
    "    groups=df.groupby(column)\n",
    "    for label in df[column].unique(): \n",
    "        group=groups.get_group(label)\n",
    "        count=len(group)    \n",
    "        if count > max_samples:\n",
    "            sampled_group=group.sample(n=max_samples, random_state=123,axis=0)\n",
    "            trimmed_df=pd.concat([trimmed_df, sampled_group], axis=0)\n",
    "        else:\n",
    "            if count>=min_samples:\n",
    "                sampled_group=group        \n",
    "                trimmed_df=pd.concat([trimmed_df, sampled_group], axis=0)\n",
    "    print('after trimming, the maximum samples in any class is now ',max_samples, ' and the minimum samples in any class is ', min_samples)\n",
    "    classes=trimmed_df[column].unique()# return this in case some classes have less than min_samples\n",
    "    class_count=len(classes) # return this in case some classes have less than min_samples\n",
    "    length=len(trimmed_df)\n",
    "    print ('the trimmed dataframe now is of length ',length, ' with ', class_count, ' classes')\n",
    "    return trimmed_df, classes, class_count\n",
    "\n",
    "max_samples=400\n",
    "min_samples=400\n",
    "column='labels'\n",
    "train_df, classes, class_count = trim(train_df, max_samples, min_samples, column)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"balance\"></a>\n",
    "## <center>Expand train_df rows with augmented images so each class has n samples</center>\n",
    "### This function is not used in this notebook. Train_df was balanced by the trim function with 400 images per class\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T23:16:59.119279Z",
     "iopub.status.busy": "2022-11-08T23:16:59.118852Z",
     "iopub.status.idle": "2022-11-08T23:16:59.136662Z",
     "shell.execute_reply": "2022-11-08T23:16:59.135617Z",
     "shell.execute_reply.started": "2022-11-08T23:16:59.119238Z"
    },
    "trusted": true
   },
   "source": [
    "def balance(df, n,column, working_dir, img_size):\n",
    "    df=df.copy()\n",
    "    print('Initial length of dataframe is ', len(df))\n",
    "    aug_dir=os.path.join(working_dir, 'aug')# directory to store augmented images\n",
    "    if os.path.isdir(aug_dir):# start with an empty directory\n",
    "        shutil.rmtree(aug_dir)\n",
    "    os.mkdir(aug_dir)        \n",
    "    for label in df[column].unique():    \n",
    "        dir_path=os.path.join(aug_dir,label)    \n",
    "        os.mkdir(dir_path) # make class directories within aug directory\n",
    "    # create and store the augmented images  \n",
    "    total=0\n",
    "    gen=ImageDataGenerator(horizontal_flip=True,  rotation_range=20, width_shift_range=.2,\n",
    "                                  height_shift_range=.2, zoom_range=.2)\n",
    "    groups=df.groupby(column) # group by class\n",
    "    for label in df[column].unique():  # for every class               \n",
    "        group=groups.get_group(label)  # a dataframe holding only rows with the specified label \n",
    "        sample_count=len(group)   # determine how many samples there are in this class  \n",
    "        if sample_count< n: # if the class has less than target number of images\n",
    "            aug_img_count=0\n",
    "            delta=n - sample_count  # number of augmented images to create\n",
    "            target_dir=os.path.join(aug_dir, label)  # define where to write the images\n",
    "            msg='{0:40s} for class {1:^30s} creating {2:^5s} augmented images'.format(' ', label, str(delta))\n",
    "            print(msg, '\\r', end='') # prints over on the same line\n",
    "            aug_gen=gen.flow_from_dataframe( group,  x_col='filepaths', y_col=None, target_size=img_size,\n",
    "                                            class_mode=None, batch_size=1, shuffle=False, \n",
    "                                            save_to_dir=target_dir, save_prefix='aug-', color_mode='rgb',\n",
    "                                            save_format='jpg')\n",
    "            while aug_img_count<delta:\n",
    "                images=next(aug_gen)            \n",
    "                aug_img_count += len(images)\n",
    "            total +=aug_img_count\n",
    "    print('Total Augmented images created= ', total)\n",
    "    # create aug_df and merge with train_df to create composite training set ndf\n",
    "    aug_fpaths=[]\n",
    "    aug_labels=[]\n",
    "    classlist=sorted(os.listdir(aug_dir))\n",
    "    for klass in classlist:\n",
    "        classpath=os.path.join(aug_dir, klass)     \n",
    "        flist=sorted(os.listdir(classpath))    \n",
    "        for f in flist:        \n",
    "            fpath=os.path.join(classpath,f)         \n",
    "            aug_fpaths.append(fpath)\n",
    "            aug_labels.append(klass)\n",
    "    Fseries=pd.Series(aug_fpaths, name='filepaths')\n",
    "    Lseries=pd.Series(aug_labels, name='labels')   \n",
    "    aug_df=pd.concat([Fseries, Lseries], axis=1)         \n",
    "    df=pd.concat([df,aug_df], axis=0).reset_index(drop=True)\n",
    "    print('Length of augmented dataframe is now ', len(df))\n",
    "    return df \n",
    "\n",
    "n=150\n",
    "column='labels'\n",
    "working_dir=r'C:\\Temp\\spiders'\n",
    "img_size=(128,128)    \n",
    "#train_df=balance(train_df, n,column, working_dir, img_size)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T23:16:59.138817Z",
     "iopub.status.busy": "2022-11-08T23:16:59.138300Z",
     "iopub.status.idle": "2022-11-08T23:16:59.387901Z",
     "shell.execute_reply": "2022-11-08T23:16:59.386967Z",
     "shell.execute_reply.started": "2022-11-08T23:16:59.138774Z"
    },
    "trusted": true
   },
   "source": [
    "# Show train_df images per label after balancing the dataset\n",
    "plot_label_count(train_df, 'labels')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"generators\"></a>\n",
    "# <center>Create the train_gen, test_gen final_test_gen and valid_gen</center>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T23:16:59.392492Z",
     "iopub.status.busy": "2022-11-08T23:16:59.392174Z",
     "iopub.status.idle": "2022-11-08T23:16:59.402761Z",
     "shell.execute_reply": "2022-11-08T23:16:59.401826Z",
     "shell.execute_reply.started": "2022-11-08T23:16:59.392465Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "source": [
    "def make_gens(batch_size, ycol, train_df, test_df, valid_df, img_size):\n",
    "    trgen=ImageDataGenerator(horizontal_flip=True)    \n",
    "    t_and_v_gen=ImageDataGenerator()\n",
    "    msg='{0:70s} for train generator'.format(' ')\n",
    "    print(msg, '\\r', end='') # prints over on the same line\n",
    "    train_gen=trgen.flow_from_dataframe(train_df, x_col='filepaths', y_col=ycol, target_size=img_size,\n",
    "                                       class_mode='categorical', color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
    "    msg='{0:70s} for valid generator'.format(' ')\n",
    "    print(msg, '\\r', end='') # prints over on the same line\n",
    "    valid_gen=t_and_v_gen.flow_from_dataframe(valid_df, x_col='filepaths', y_col=ycol, target_size=img_size,\n",
    "                                       class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=batch_size)\n",
    "    # for the test_gen we want to calculate the batch size and test steps such that batch_size X test_steps= number of samples in test set\n",
    "    # this insures that we go through all the sample in the test set exactly once.\n",
    "    length=len(test_df)\n",
    "    test_batch_size=sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and length/n<=80],reverse=True)[0]  \n",
    "    test_steps=int(length/test_batch_size)    \n",
    "    msg='{0:70s} for test generator'.format(' ')\n",
    "    print(msg, '\\r', end='') # prints over on the same line\n",
    "    test_gen=t_and_v_gen.flow_from_dataframe(test_df, x_col='filepaths', y_col=ycol, target_size=img_size,\n",
    "                                       class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=test_batch_size)\n",
    "    # from the generator we can get information we will need later\n",
    "    classes=list(train_gen.class_indices.keys())\n",
    "    class_indices=list(train_gen.class_indices.values())\n",
    "    class_count=len(classes)\n",
    "    labels=test_gen.labels\n",
    "    print ( 'test batch size: ' ,test_batch_size, '  test steps: ', test_steps, ' number of classes : ', class_count)\n",
    "    return train_gen, test_gen, valid_gen, test_steps\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T23:16:59.404739Z",
     "iopub.status.busy": "2022-11-08T23:16:59.404391Z",
     "iopub.status.idle": "2022-11-08T23:16:59.458476Z",
     "shell.execute_reply": "2022-11-08T23:16:59.457509Z",
     "shell.execute_reply.started": "2022-11-08T23:16:59.404703Z"
    },
    "trusted": true
   },
   "source": [
    "img_size=(145, 145)\n",
    "batch_size=20\n",
    "ycol='labels'\n",
    "train_gen, test_gen, valid_gen, test_steps= make_gens(batch_size, ycol, train_df, test_df, valid_df, img_size)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"show\"></a>\n",
    "# <center>Create a function to show example training images</center>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T23:16:59.460365Z",
     "iopub.status.busy": "2022-11-08T23:16:59.459994Z",
     "iopub.status.idle": "2022-11-08T23:17:02.211130Z",
     "shell.execute_reply": "2022-11-08T23:17:02.210099Z",
     "shell.execute_reply.started": "2022-11-08T23:16:59.460310Z"
    },
    "trusted": true
   },
   "source": [
    "def show_image_samples(gen ):\n",
    "    t_dict=gen.class_indices\n",
    "    classes=list(t_dict.keys())    \n",
    "    images,labels=next(gen) # get a sample batch from the generator \n",
    "    plt.figure(figsize=(25, 25))\n",
    "    length=len(labels)\n",
    "    if length<25:   #show maximum of 25 images\n",
    "        r=length\n",
    "    else:\n",
    "        r=25\n",
    "    for i in range(r):        \n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        image=images[i] /255       \n",
    "        plt.imshow(image)\n",
    "        index=np.argmax(labels[i])\n",
    "        class_name=classes[index]\n",
    "        plt.title(class_name, color='blue', fontsize=18)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "show_image_samples(train_gen )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"f1metric\"></a>\n",
    "# <center>Create a function to calculate the F1 score metric</center>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T23:17:02.213458Z",
     "iopub.status.busy": "2022-11-08T23:17:02.212833Z",
     "iopub.status.idle": "2022-11-08T23:17:02.225664Z",
     "shell.execute_reply": "2022-11-08T23:17:02.223746Z",
     "shell.execute_reply.started": "2022-11-08T23:17:02.213419Z"
    },
    "trusted": true
   },
   "source": [
    "def F1_score(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>\n",
    "# <center>Create a model using transfer learning with EfficientNetB3</center>\n",
    "### NOTE experts advise you make the base model initially not trainable when you do transfer learning.   \n",
    "### Then train for some number of epochs then fine tune model by making base model trainable and run more epochs\n",
    "### I have found this to be WRONG!!!!\n",
    "### Making the base model trainable from the outset leads to faster convegence and a lower validation loss\n",
    "### for the same number of total epochs! Insure  you initialize the transfer model with imagenet weights"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T23:17:02.227890Z",
     "iopub.status.busy": "2022-11-08T23:17:02.227546Z",
     "iopub.status.idle": "2022-11-08T23:17:04.788063Z",
     "shell.execute_reply": "2022-11-08T23:17:04.786986Z",
     "shell.execute_reply.started": "2022-11-08T23:17:02.227854Z"
    },
    "trusted": true
   },
   "source": [
    "def make_model(img_size, lr, mod_num=3):  \n",
    "    img_shape=(img_size[0], img_size[1], 3)\n",
    "    if mod_num == 0:\n",
    "        base_model=tf.keras.applications.efficientnet.EfficientNetB0(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max')\n",
    "        msg='Created EfficientNet B0 model'\n",
    "    elif mod_num == 3:\n",
    "        base_model=tf.keras.applications.efficientnet.EfficientNetB3(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max') \n",
    "        msg='Created EfficientNet B3 model'\n",
    "    elif mod_num == 5:\n",
    "        base_model=tf.keras.applications.efficientnet.EfficientNetB5(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max') \n",
    "        msg='Created EfficientNet B5 model'\n",
    "        \n",
    "    else:\n",
    "        base_model=tf.keras.applications.efficientnet.EfficientNetB7(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max')\n",
    "        msg='Created EfficientNet B7 model'   \n",
    "   \n",
    "    base_model.trainable=True\n",
    "    x=base_model.output\n",
    "    x=BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n",
    "    x = Dense(256, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n",
    "                    bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\n",
    "    x=Dropout(rate=.4, seed=123)(x)       \n",
    "    output=Dense(class_count, activation='softmax')(x)\n",
    "    model=Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(Adamax(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy', F1_score]) \n",
    "    msg=msg + f' with initial learning rate set to {lr}'\n",
    "    print_in_color(msg)\n",
    "    return model\n",
    "\n",
    "lr=.001\n",
    "model=make_model(img_size, lr) # using B3 model by default"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"callback\"></a>\n",
    "# <center>Create a custom Keras callback to continue and optionally set LR or halt training</center>\n",
    "The LR_ASK callback is a convenient callback that allows you to continue training for ask_epoch more epochs or to halt training.  \n",
    "If you elect to continue training for more epochs you are given the option to retain the current learning rate (LR) or to  \n",
    "enter a new value for the learning rate. The form of use is:  \n",
    "ask=LR_ASK(model,epochs, ask_epoch) where:  \n",
    "* model is a string which is the name of your compiled model\n",
    "* epochs is an integer which is the number of epochs to run specified in model.fit\n",
    "* ask_epoch is an integer. If ask_epoch is set to a value say 5 then the model will train for 5 epochs.  \n",
    "  then the user is ask to enter H to halt training, or enter an inter value. For example if you enter 4  \n",
    "  training will continue for 4 more epochs to epoch 9 then you will be queried again. Once you enter an  \n",
    "  integer value you are prompted to press ENTER to continue training using the current learning rate  \n",
    "  or to enter a new value for the learning rate.\n",
    " * dwell is a boolean. If set to true the function compares the validation loss for the current tp the lowest   \n",
    "   validation loss thus far achieved. If the validation loss for the current epoch is larger then learning rate  \n",
    "   is automatically adjust by the formulanew_lr=lr * factor where factor is a float between 0 and 1. The motivation  \n",
    "   here is that if the validatio loss increased we have moved to a point in Nspace on the cost functiob surface that  \n",
    "   if less favorable(higher cost) than for the epoch with the lowest cost. So the model is loaded with the weights\n",
    "   from the epoch with the lowest loss and the learning rate is reduced\n",
    "  \n",
    " At the end of training the model weights are set to the weights for the epoch that achieved the lowest validation loss"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T23:17:04.790213Z",
     "iopub.status.busy": "2022-11-08T23:17:04.789798Z",
     "iopub.status.idle": "2022-11-08T23:17:04.815833Z",
     "shell.execute_reply": "2022-11-08T23:17:04.814758Z",
     "shell.execute_reply.started": "2022-11-08T23:17:04.790174Z"
    },
    "trusted": true
   },
   "source": [
    "class LR_ASK(keras.callbacks.Callback):\n",
    "    def __init__ (self, model, epochs,  ask_epoch, dwell=True, factor=.4): # initialization of the callback\n",
    "        super(LR_ASK, self).__init__()\n",
    "        self.model=model               \n",
    "        self.ask_epoch=ask_epoch\n",
    "        self.epochs=epochs\n",
    "        self.ask=True # if True query the user on a specified epoch\n",
    "        self.lowest_vloss=np.inf\n",
    "        self.lowest_aloss=np.inf\n",
    "        self.best_weights=self.model.get_weights() # set best weights to model's initial weights\n",
    "        self.best_epoch=1\n",
    "        self.plist=[]\n",
    "        self.alist=[]\n",
    "        self.dwell= dwell\n",
    "        self.factor=factor\n",
    "        \n",
    "    def get_list(self): # define a function to return the list of % validation change\n",
    "        return self.plist, self.alist\n",
    "    def on_train_begin(self, logs=None): # this runs on the beginning of training\n",
    "        if self.ask_epoch == 0: \n",
    "            print('you set ask_epoch = 0, ask_epoch will be set to 1', flush=True)\n",
    "            self.ask_epoch=1\n",
    "        if self.ask_epoch >= self.epochs: # you are running for epochs but ask_epoch>epochs\n",
    "            print('ask_epoch >= epochs, will train for ', epochs, ' epochs', flush=True)\n",
    "            self.ask=False # do not query the user\n",
    "        if self.epochs == 1:\n",
    "            self.ask=False # running only for 1 epoch so do not query user\n",
    "        else:\n",
    "            msg =f'Training will proceed until epoch {ask_epoch} then you will be asked to' \n",
    "            print_in_color(msg )\n",
    "            msg='enter H to halt training or enter an integer for how many more epochs to run then be asked again'\n",
    "            print_in_color(msg)\n",
    "            if self.dwell:\n",
    "                msg='learning rate will be automatically adjusted during training'\n",
    "                print_in_color(msg, (0,255,0))\n",
    "        self.start_time= time.time() # set the time at which training started\n",
    "       \n",
    "    def on_train_end(self, logs=None):   # runs at the end of training  \n",
    "        msg=f'loading model with weights from epoch {self.best_epoch}'\n",
    "        print_in_color(msg, (0,255,255))\n",
    "        self.model.set_weights(self.best_weights) # set the weights of the model to the best weights\n",
    "        tr_duration=time.time() - self.start_time   # determine how long the training cycle lasted         \n",
    "        hours = tr_duration // 3600\n",
    "        minutes = (tr_duration - (hours * 3600)) // 60\n",
    "        seconds = tr_duration - ((hours * 3600) + (minutes * 60))\n",
    "        msg = f'training elapsed time was {str(hours)} hours, {minutes:4.1f} minutes, {seconds:4.2f} seconds)'\n",
    "        print_in_color (msg) # print out training duration time\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):  # method runs on the end of each epoch\n",
    "        vloss=logs.get('val_loss')  # get the validation loss for this epoch\n",
    "        aloss=logs.get('loss')\n",
    "        if epoch >0:\n",
    "            deltav = self.lowest_vloss- vloss \n",
    "            pimprov=(deltav/self.lowest_vloss) * 100 \n",
    "            self.plist.append(pimprov)\n",
    "            deltaa=self.lowest_aloss-aloss\n",
    "            aimprov=(deltaa/self.lowest_aloss) * 100\n",
    "            self.alist.append(aimprov)\n",
    "        else:\n",
    "            pimprov=0.0 \n",
    "            aimprov=0.0\n",
    "        if vloss< self.lowest_vloss:\n",
    "            self.lowest_vloss=vloss\n",
    "            self.best_weights=self.model.get_weights() # set best weights to model's initial weights\n",
    "            self.best_epoch=epoch + 1            \n",
    "            msg=f'\\n validation loss of {vloss:7.4f} is {pimprov:7.4f} % below lowest loss, saving weights from epoch {str(epoch + 1):3s} as best weights'\n",
    "            print_in_color(msg, (0,255,0)) # green foreground\n",
    "        else: # validation loss increased\n",
    "            pimprov=abs(pimprov)\n",
    "            msg=f'\\n validation loss of {vloss:7.4f} is {pimprov:7.4f} % above lowest loss of {self.lowest_vloss:7.4f} keeping weights from epoch {str(self.best_epoch)} as best weights'\n",
    "            print_in_color(msg, (255,255,0)) # yellow foreground\n",
    "            if self.dwell: # if dwell is True when the validation loss increases the learning rate is automatically reduced and model weights are set to best weights\n",
    "                lr=float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n",
    "                new_lr=lr * self.factor\n",
    "                msg=f'learning rate was automatically adjusted from {lr:8.6f} to {new_lr:8.6f}, model weights set to best weights'\n",
    "                print_in_color(msg) # cyan foreground\n",
    "                tf.keras.backend.set_value(self.model.optimizer.lr, new_lr) # set the learning rate in the optimizer\n",
    "                self.model.set_weights(self.best_weights) # set the weights of the model to the best weights      \n",
    "                \n",
    "        if aloss< self.lowest_aloss:\n",
    "            self.lowest_aloss=aloss        \n",
    "        if self.ask: # are the conditions right to query the user?\n",
    "            if epoch + 1 ==self.ask_epoch: # is this epoch the one for quering the user?\n",
    "                msg='press enter to continue or enter a comment  below '\n",
    "                print_in_color(msg)\n",
    "                comment=input(' ')\n",
    "                if comment !='':\n",
    "                    comment = 'User comment: ' + comment\n",
    "                    print_in_color(comment, (155,245,66))\n",
    "                msg='\\n Enter H to end training or  an integer for the number of additional epochs to run then ask again'\n",
    "                print_in_color(msg) # cyan foreground\n",
    "                ans=input()\n",
    "                \n",
    "                if ans == 'H' or ans =='h' or ans == '0': # quit training for these conditions\n",
    "                    msg=f'you entered {ans},  Training halted on epoch {epoch+1} due to user input\\n'\n",
    "                    print_in_color(msg)\n",
    "                    self.model.stop_training = True # halt training\n",
    "                else: # user wants to continue training\n",
    "                    self.ask_epoch += int(ans)\n",
    "                    if self.ask_epoch > self.epochs:\n",
    "                        print('\\nYou specified maximum epochs of as ', self.epochs, ' cannot train for ', self.ask_epoch, flush =True)\n",
    "                    else:\n",
    "                        msg=f'you entered {ans} Training will continue to epoch {self.ask_epoch}'\n",
    "                        print_in_color(msg) # cyan foreground\n",
    "                        if self.dwell==False:\n",
    "                            lr=float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n",
    "                            msg=f'current LR is  {lr:8.6f}  hit enter to keep  this LR or enter a new LR'\n",
    "                            print_in_color(msg) # cyan foreground\n",
    "                            ans=input(' ')\n",
    "                            if ans =='':\n",
    "                                msg=f'keeping current LR of {lr:7.5f}'\n",
    "                                print_in_color(msg) # cyan foreground\n",
    "                            else:\n",
    "                                new_lr=float(ans)\n",
    "                                tf.keras.backend.set_value(self.model.optimizer.lr, new_lr) # set the learning rate in the optimizer\n",
    "                                msg=f' changing LR to {ans}'\n",
    "                                print_in_color(msg) # cyan foreground"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"callbacks\"></a>\n",
    "# <center>Instantiate custom callback "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T23:17:04.818309Z",
     "iopub.status.busy": "2022-11-08T23:17:04.817396Z",
     "iopub.status.idle": "2022-11-08T23:17:04.951950Z",
     "shell.execute_reply": "2022-11-08T23:17:04.950830Z",
     "shell.execute_reply.started": "2022-11-08T23:17:04.818281Z"
    },
    "trusted": true
   },
   "source": [
    "epochs=40\n",
    "ask_epoch=10\n",
    "ask=LR_ASK(model, epochs,  ask_epoch)\n",
    "callbacks=[ask]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play a blues song while your model is training\n",
    "## BB King Blues Boys from Montreux 1993"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T23:17:04.954138Z",
     "iopub.status.busy": "2022-11-08T23:17:04.953768Z",
     "iopub.status.idle": "2022-11-08T23:17:05.013923Z",
     "shell.execute_reply": "2022-11-08T23:17:05.012974Z",
     "shell.execute_reply.started": "2022-11-08T23:17:04.954103Z"
    },
    "trusted": true
   },
   "source": [
    "video = YouTubeVideo('AU432SxopNM')\n",
    "display(video)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"train\"></a>\n",
    "# <center>Train the model\n",
    "### Note unlike how you are told it is BETTER to make the base model trainable from the outset if you are doing transfer learning\n",
    "### The model will converge faster and have a lower validation losss. Ensure you initialize the transfer model with imagenet weights.  \n",
    "### I have done a lot of testing running both ways hand have always found this to be true"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T23:17:05.015971Z",
     "iopub.status.busy": "2022-11-08T23:17:05.015119Z",
     "iopub.status.idle": "2022-11-08T23:30:42.696680Z",
     "shell.execute_reply": "2022-11-08T23:30:42.695736Z",
     "shell.execute_reply.started": "2022-11-08T23:17:05.015936Z"
    },
    "trusted": true
   },
   "source": [
    "\n",
    "history=model.fit(x=train_gen,   epochs=epochs, verbose=1, callbacks=callbacks,  validation_data=valid_gen,\n",
    "               validation_steps=None,  shuffle=False,  initial_epoch=0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"plot\"></a>\n",
    "# <center>Define a function to plot the training data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T23:30:42.698981Z",
     "iopub.status.busy": "2022-11-08T23:30:42.698294Z",
     "iopub.status.idle": "2022-11-08T23:31:28.069029Z",
     "shell.execute_reply": "2022-11-08T23:31:28.067982Z",
     "shell.execute_reply.started": "2022-11-08T23:30:42.698930Z"
    },
    "trusted": true
   },
   "source": [
    "def tr_plot(tr_data):\n",
    "    start_epoch=0\n",
    "    #Plot the training and validation data\n",
    "    tacc=tr_data.history['accuracy']\n",
    "    tloss=tr_data.history['loss']\n",
    "    vacc=tr_data.history['val_accuracy']\n",
    "    vloss=tr_data.history['val_loss']\n",
    "    tf1=tr_data.history['F1_score']\n",
    "    vf1=tr_data.history['val_F1_score']\n",
    "    Epoch_count=len(tacc)+ start_epoch\n",
    "    Epochs=[]\n",
    "    for i in range (start_epoch ,Epoch_count):\n",
    "        Epochs.append(i+1)   \n",
    "    index_loss=np.argmin(vloss)#  this is the epoch with the lowest validation loss\n",
    "    val_lowest=vloss[index_loss]\n",
    "    index_acc=np.argmax(vacc)\n",
    "    acc_highest=vacc[index_acc]\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    sc_label='best epoch= '+ str(index_loss+1 +start_epoch)\n",
    "    vc_label='best epoch= '+ str(index_acc + 1+ start_epoch)\n",
    "    fig,axes=plt.subplots(nrows=1, ncols=3, figsize=(25,10))\n",
    "    axes[0].plot(Epochs,tloss, 'r', label='Training loss')\n",
    "    axes[0].plot(Epochs,vloss,'g',label='Validation loss' )\n",
    "    axes[0].scatter(index_loss+1 +start_epoch,val_lowest, s=150, c= 'blue', label=sc_label)\n",
    "    axes[0].scatter(Epochs, tloss, s=100, c='red')    \n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].set_xlabel('Epochs', fontsize=18)\n",
    "    axes[0].set_ylabel('Loss', fontsize=18)\n",
    "    axes[0].legend()\n",
    "    axes[1].plot (Epochs,tacc,'r',label= 'Training Accuracy')\n",
    "    axes[1].scatter(Epochs, tacc, s=100, c='red')\n",
    "    axes[1].plot (Epochs,vacc,'g',label= 'Validation Accuracy')\n",
    "    axes[1].scatter(index_acc+1 +start_epoch,acc_highest, s=150, c= 'blue', label=vc_label)\n",
    "    axes[1].set_title('Training and Validation Accuracy')\n",
    "    axes[1].set_xlabel('Epochs', fontsize=18)\n",
    "    axes[1].set_ylabel('Accuracy', fontsize=18)\n",
    "    axes[1].legend()\n",
    "    axes[2].plot (Epochs,tf1,'r',label= 'Training F1 score')    \n",
    "    axes[2].plot (Epochs,vf1,'g',label= 'Validation F1 score')\n",
    "    index_tf1=np.argmax(tf1)#  this is the epoch with the highest training F1 score\n",
    "    tf1max=tf1[index_tf1]\n",
    "    index_vf1=np.argmax(vf1)# thisiis the epoch with the highest validation F1 score\n",
    "    vf1max=vf1[index_vf1]\n",
    "    axes[2].scatter(index_vf1+1 +start_epoch,vf1max, s=150, c= 'blue', label=vc_label)    \n",
    "    axes[2].scatter(Epochs, tf1, s=100, c='red')\n",
    "    axes[2].set_title('Training and Validation F1 score')\n",
    "    axes[2].set_xlabel('Epochs', fontsize=18)\n",
    "    axes[2].set_ylabel('F1  score', fontsize=18)\n",
    "    axes[2].legend()\n",
    "    \n",
    "    plt.tight_layout    \n",
    "    plt.show()\n",
    "    return \n",
    "    \n",
    "tr_plot(history)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"result\"></a>\n",
    "# <center>Make Predictions on the test set</center>\n",
    "### Define a function which takes in a test generator  and generates predictions on the test set including a confusion matrix and a classification report"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T23:31:28.071460Z",
     "iopub.status.busy": "2022-11-08T23:31:28.070772Z",
     "iopub.status.idle": "2022-11-08T23:31:34.456723Z",
     "shell.execute_reply": "2022-11-08T23:31:34.455716Z",
     "shell.execute_reply.started": "2022-11-08T23:31:28.071417Z"
    },
    "trusted": true
   },
   "source": [
    "def predictor(test_gen):    \n",
    "    y_pred= []\n",
    "    error_list=[]\n",
    "    error_pred_list = []\n",
    "    y_true=test_gen.labels\n",
    "    classes=list(test_gen.class_indices.keys())\n",
    "    class_count=len(classes)\n",
    "    errors=0\n",
    "    preds=model.predict(test_gen, verbose=1)\n",
    "    tests=len(preds)    \n",
    "    for i, p in enumerate(preds):        \n",
    "        pred_index=np.argmax(p)         \n",
    "        true_index=test_gen.labels[i]  # labels are integer values        \n",
    "        if pred_index != true_index: # a misclassification has occurred                                           \n",
    "            errors=errors + 1\n",
    "            file=test_gen.filenames[i]\n",
    "            error_list.append(file)\n",
    "            error_class=classes[pred_index]\n",
    "            error_pred_list.append(error_class)\n",
    "        y_pred.append(pred_index)\n",
    "            \n",
    "    acc=( 1-errors/tests) * 100\n",
    "    msg=f'there were {errors} errors in {tests} tests for an accuracy of {acc:6.2f}'\n",
    "    print_in_color(msg, (0,255,255), (100,100,100)) # cyan foreground\n",
    "    ypred=np.array(y_pred)\n",
    "    ytrue=np.array(y_true)\n",
    "    f1score=f1_score(ytrue, ypred, average='weighted')* 100\n",
    "    if class_count <=30:\n",
    "        cm = confusion_matrix(ytrue, ypred )\n",
    "        # plot the confusion matrix\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n",
    "        plt.xticks(np.arange(class_count)+.5, classes, rotation=90)\n",
    "        plt.yticks(np.arange(class_count)+.5, classes, rotation=0)\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.show()\n",
    "    clr = classification_report(y_true, y_pred, target_names=classes, digits= 4) # create classification report\n",
    "    print(\"Classification Report:\\n----------------------\\n\", clr)\n",
    "    return errors, tests, error_list, error_pred_list, f1score\n",
    "\n",
    "errors, tests, error_list, error_pred_list, f1score =predictor(test_gen)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"perrors\"></a>\n",
    "# <center>If the are less than 50 misclassifications print the misclassified files </a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T23:31:34.458655Z",
     "iopub.status.busy": "2022-11-08T23:31:34.458294Z",
     "iopub.status.idle": "2022-11-08T23:31:34.467842Z",
     "shell.execute_reply": "2022-11-08T23:31:34.466734Z",
     "shell.execute_reply.started": "2022-11-08T23:31:34.458619Z"
    },
    "trusted": true
   },
   "source": [
    "def print_errors(error_list):\n",
    "    if len(error_list) == 0:\n",
    "        print_in_color('There were no errors in predicting the test set')\n",
    "    else:\n",
    "        if len(error_list)>50:\n",
    "            print_in_color('There were over 50 misclassifications, the error list will not be printed')\n",
    "        else:\n",
    "            print ('Below is a list of test files that were miss classified \\n')\n",
    "            print ('{0:^30s}{1:^30s}'.format('Test File', ' Predicted as'))            \n",
    "            for i in range(len(error_list)):\n",
    "                fpath=error_list[i]                \n",
    "                split=fpath.split('/') \n",
    "                slength=len(split)\n",
    "                f=split[slength-2]+ '-' + split[slength-1]\n",
    "                print(f'{f:^30s}{error_pred_list[i]:^30s}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T23:31:34.469948Z",
     "iopub.status.busy": "2022-11-08T23:31:34.469348Z",
     "iopub.status.idle": "2022-11-08T23:31:34.486420Z",
     "shell.execute_reply": "2022-11-08T23:31:34.485157Z",
     "shell.execute_reply.started": "2022-11-08T23:31:34.469906Z"
    },
    "trusted": true
   },
   "source": [
    "print_errors(error_list)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"serrors\"></a>\n",
    "# <center>Define a function to show up to 10 misclassified test images and a sample of predicted class </center>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T23:31:34.488734Z",
     "iopub.status.busy": "2022-11-08T23:31:34.488216Z",
     "iopub.status.idle": "2022-11-08T23:31:37.112917Z",
     "shell.execute_reply": "2022-11-08T23:31:37.110116Z",
     "shell.execute_reply.started": "2022-11-08T23:31:34.488700Z"
    },
    "trusted": true
   },
   "source": [
    "def show_misclassification(error_list, error_pred_list, test_gen):\n",
    "    if len(error_list) == 0:\n",
    "        print_in_color('there were no errors in predicting the test images')    \n",
    "    else:\n",
    "        if len(error_list)<10:\n",
    "            length=len(error_list)\n",
    "        else:\n",
    "            length = 10 # show 10 images        \n",
    "        msg='The images below show 10 misclassified test images on left and an example of an image in the  misclassified class'\n",
    "        print_in_color(msg)        \n",
    "        length=10  \n",
    "        test_files=test_gen.filenames\n",
    "        plt.figure(figsize=(15, length * 5))\n",
    "        for i in range(length):\n",
    "            fpath=error_list[i] \n",
    "            test_img=plt.imread(fpath)\n",
    "            pred_class= error_pred_list[i]\n",
    "            # find a test file that is the same class as the pred_class\n",
    "            for f in test_gen.filenames:\n",
    "                split=list(f.split('/'))                \n",
    "                klass=split[len(split)-2]\n",
    "                if klass == pred_class:\n",
    "                    pred_img_path= f      \n",
    "            pred_img=plt.imread(pred_img_path)\n",
    "            for j in range(2):   \n",
    "                k=i*2 + j + 1            \n",
    "                plt.subplot(length, 2, k)\n",
    "                plt.axis('off')\n",
    "                if j == 0:\n",
    "                    plt.imshow(test_img)\n",
    "                    split=fpath.split('/')\n",
    "                    slength=len(split)\n",
    "                    #print (split)\n",
    "                    title=split[slength-2]+ '-' + split[slength-1]\n",
    "                    title='TEST IMAGE\\n'+ title\n",
    "                    plt.title(title, color='blue', fontsize=16)\n",
    "                else:                \n",
    "                    plt.imshow(pred_img)\n",
    "                    split=pred_img_path.split('/')\n",
    "                    slength=len(split)\n",
    "                    title=split[slength-2]+ '-' + split[slength-1]\n",
    "                    title='PREDICTED CLASS EXAMPLE\\n'+ title\n",
    "                    plt.title(title, color='blue', fontsize=16)\n",
    "        plt.show()\n",
    "\n",
    "show_misclassification(error_list, error_pred_list, test_gen)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"save\"></a>\n",
    "# <center>Save the model </a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T23:31:37.115134Z",
     "iopub.status.busy": "2022-11-08T23:31:37.114564Z",
     "iopub.status.idle": "2022-11-08T23:31:37.121674Z",
     "shell.execute_reply": "2022-11-08T23:31:37.120886Z",
     "shell.execute_reply.started": "2022-11-08T23:31:37.115099Z"
    },
    "trusted": true
   },
   "source": [
    "def save_model(subject, classes, img_size, f1score, working_dir):\n",
    "    name=subject + '-' + str(len(classes)) + '-(' + str(img_size[0]) + ' X ' + str(img_size[1]) + ')'\n",
    "    save_id=f'{name}-{f1score:5.2f}.h5'\n",
    "    model_save_loc=os.path.join(working_dir, save_id)\n",
    "    model.save(model_save_loc)\n",
    "    msg= f'model was saved as {model_save_loc}'\n",
    "    print_in_color(msg, (0,255,255), (100,100,100)) # cyan foreground"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T23:31:37.126771Z",
     "iopub.status.busy": "2022-11-08T23:31:37.126119Z",
     "iopub.status.idle": "2022-11-08T23:31:38.298018Z",
     "shell.execute_reply": "2022-11-08T23:31:38.297020Z",
     "shell.execute_reply.started": "2022-11-08T23:31:37.126723Z"
    },
    "trusted": true
   },
   "source": [
    "working_dir=r'./'\n",
    "subject='grapes'\n",
    "save_model(subject, classes, img_size, f1score, working_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
